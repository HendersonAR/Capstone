---
title: "Random Forest, Visuals"
author: "Andrew Henderson"
date: "2025-03-31"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
if (!require(randomForest)) install.packages("randomForest", dependencies = TRUE)
if (!require(caret)) install.packages("caret", dependencies = TRUE)

library(randomForest)
library(caret)
library(dplyr)
library(kableExtra)
library(grid)
library(gridExtra)
library(stringr)
```

```{r}
data <- read.csv("transfer_dataset.csv", stringsAsFactors = T)
```

```{r}

data$transfer <- as.factor(data$transfer)
data$MF <- as.factor(data$MF)
data$DF <- as.factor(data$DF)
data$FW <- as.factor(data$FW)

data <- na.omit(data)
```

## Normal RF without Sampling Adjustments

```{r}
set.seed(42)

# Helper to split into Train (60%), Validation (20%), Test (20%)
three_way_split <- function(df, response) {
  # 60% Train
  idx_train <- createDataPartition(df[[response]], p = 0.6, list = FALSE)
  train <- df[idx_train, ]
  temp  <- df[-idx_train, ]
  # Of the remaining 40%, split half/half into validation & test (each 20% of original)
  idx_val <- createDataPartition(temp[[response]], p = 0.5, list = FALSE)
  validation <- temp[idx_val, ]
  test       <- temp[-idx_val, ]
  list(train = train, validation = validation, test = test)
}

# Positions to loop through
positions <- c("MF", "FW", "DF")

# Storage
models_val     <- list()
conf_matrices  <- list()

for (pos in positions) {
  
  # 1) Subset & clean
  pos_data <- subset(data, data[[pos]] == 1)
  pos_data <- pos_data[, !names(pos_data) %in% c("season","player","MF","FW","DF")]
  pos_data$transfer <- as.factor(pos_data$transfer)
  
  if(nrow(pos_data) < 50) {
    cat("Not enough data for", pos, "\n"); next
  }
  
  # 2) Three-way split
  splits <- three_way_split(pos_data, "transfer")
  train      <- splits$train
  validation <- splits$validation
  # (You can also keep splits$test if you wish to hold out a final test set.)
  
  # 3) Down-sample training only
  down <- downSample(
    x     = train[, setdiff(names(train), "transfer")],
    y     = train$transfer,
    yname = "transfer"
  )
  
  # 4) Train RF on down-sampled training set
  rf_mod <- randomForest(
    transfer ~ .,
    data   = down,
    ntree  = 500,
    mtry   = floor(sqrt(ncol(down) - 1)),
    importance = TRUE
  )
  models_val[[pos]] <- rf_mod
  
  # 5) Evaluate on the validation set
  preds <- predict(rf_mod, validation)
  cm    <- confusionMatrix(preds, validation$transfer)
  conf_matrices[[pos]] <- cm
  
  cat("\n===", pos, "Players: Validation Performance ===\n")
  print(cm)
}

```

```{r}
library(caret)
library(randomForest)

set.seed(42)
positions <- c("MF", "FW", "DF")

for (pos in positions) {
  
  # 1) Subset & clean
  pos_data <- subset(data, data[[pos]] == 1)
  pos_data <- pos_data[, !names(pos_data) %in% c("season", "player", "MF", "FW", "DF")]
  pos_data$transfer <- as.factor(pos_data$transfer)
  
  # 2) Three‐way split: 60% train, 20% test, 20% validation
  idx_train <- createDataPartition(pos_data$transfer, p = 0.6, list = FALSE)
  trainData <- pos_data[idx_train, ]
  temp      <- pos_data[-idx_train, ]
  
  idx_test  <- createDataPartition(temp$transfer, p = 0.5, list = FALSE)
  testData  <- temp[idx_test, ]
  validData <- temp[-idx_test, ]
  
  # 3) Down‐sample and up‐sample the TRAINING set
  train_down <- downSample(
    x     = trainData[, setdiff(names(trainData), "transfer")],
    y     = trainData$transfer,
    yname = "transfer"
  )
  train_up <- upSample(
    x     = trainData[, setdiff(names(trainData), "transfer")],
    y     = trainData$transfer,
    yname = "transfer"
  )
  
  # 4) Fit RF on each sampled training set
  rf_down <- randomForest(
    transfer ~ .,
    data  = train_down,
    ntree = 500,
    mtry  = floor(sqrt(ncol(train_down) - 1))
  )
  rf_up <- randomForest(
    transfer ~ .,
    data  = train_up,
    ntree = 500,
    mtry  = floor(sqrt(ncol(train_up) - 1))
  )
  
  # 6) Predict & evaluate on VALIDATION set
  cat("\n---", pos, "Players: Down‐Sampled Model (Validation) ---\n")
  pred_val_down <- predict(rf_down, validData)
  print(confusionMatrix(pred_val_down, validData$transfer))
  
  cat("\n---", pos, "Players: Up‐Sampled Model (Validation) ---\n")
  pred_val_up <- predict(rf_up, validData)
  print(confusionMatrix(pred_val_up, validData$transfer))
}

```
## Creating Kable Table to compare results

```{r}
summary_df <- data.frame(
  Position    = character(),
  Sampling    = character(),
  Dataset     = character(),
  Accuracy    = numeric(),
  Sensitivity = numeric(),
  Specificity = numeric(),
  stringsAsFactors = FALSE
)

for (pos in positions) {
  
  # ... your three‐way split, down/up‐sampling, and model fitting here ...
  # (trainData, validData, rf_down, rf_up, testData, etc.)
  
  # 5) Predict & evaluate on TEST set
  cm_test_down <- confusionMatrix(predict(rf_down, testData), testData$transfer)
  cm_test_up   <- confusionMatrix(predict(rf_up,   testData), testData$transfer)
  
  # 6) Predict & evaluate on VALIDATION set
  cm_val_down <- confusionMatrix(predict(rf_down, validData), validData$transfer)
  cm_val_up   <- confusionMatrix(predict(rf_up,   validData), validData$transfer)
  
  # Append each result to summary_df
  summary_df <- rbind(
    summary_df,
    data.frame(
      Position    = pos,
      Sampling    = "Down",
      Dataset     = "Test",
      Accuracy    = cm_test_down$overall["Accuracy"],
      Sensitivity = cm_test_down$byClass["Sensitivity"],
      Specificity = cm_test_down$byClass["Specificity"],
      stringsAsFactors = FALSE
    ),
    data.frame(
      Position    = pos,
      Sampling    = "Up",
      Dataset     = "Test",
      Accuracy    = cm_test_up$overall["Accuracy"],
      Sensitivity = cm_test_up$byClass["Sensitivity"],
      Specificity = cm_test_up$byClass["Specificity"],
      stringsAsFactors = FALSE
    ),
    data.frame(
      Position    = pos,
      Sampling    = "Down",
      Dataset     = "Validation",
      Accuracy    = cm_val_down$overall["Accuracy"],
      Sensitivity = cm_val_down$byClass["Sensitivity"],
      Specificity = cm_val_down$byClass["Specificity"],
      stringsAsFactors = FALSE
    ),
    data.frame(
      Position    = pos,
      Sampling    = "Up",
      Dataset     = "Validation",
      Accuracy    = cm_val_up$overall["Accuracy"],
      Sensitivity = cm_val_up$byClass["Sensitivity"],
      Specificity = cm_val_up$byClass["Specificity"],
      stringsAsFactors = FALSE
    )
  )
}

# Finally, print the comparison table
kable(
  summary_df,
  digits  = 3,
  caption = "RF Performance by Position, Sampling & Dataset"
)
```

```{r}
# --- Midfielders ---
mf_data <- subset(data, MF == 1)
mf_data$transfer <- factor(mf_data$transfer)
mf_splits <- three_way_split(mf_data, "transfer")
mf_train  <- mf_splits$train
mf_val    <- mf_splits$validation

# down‐sample & fit
mf_down <- downSample(
  x     = mf_train[, setdiff(names(mf_train), "transfer")],
  y     = mf_train$transfer,
  yname = "transfer"
)
mf_rf    <- randomForest(
  transfer ~ .,
  data   = mf_down,
  ntree  = 500,
  mtry   = floor(sqrt(ncol(mf_down) - 1))
)

# predictions & confusionMatrix
mf_preds         <- predict(mf_rf, mf_val)
mf_conf_matrix   <- confusionMatrix(factor(mf_preds), factor(mf_val$transfer))
mf_conf_df       <- as.data.frame(mf_conf_matrix$table)
mf_conf_df$Prediction <- factor(
  mf_conf_df$Prediction,
  levels = c("0","1"),
  labels = c("no transfer","transferred")
)
mf_conf_df$Reference  <- factor(
  mf_conf_df$Reference,
  levels = c("0","1"),
  labels = c("no transfer","transferred")
)
mf_total_obs     <- sum(mf_conf_matrix$table)
mf_conf_df$Proportion <- mf_conf_df$Freq / mf_total_obs

mf_conf_matrix_g <- ggplot(mf_conf_df, aes(x = Prediction, y = Reference)) +
  geom_tile(fill = "white", color = "black") +
  geom_text(aes(label = paste0(
    Freq, " (", sprintf("%.2f", Proportion * 100), "%)"
  )), size = 5) +
  theme_minimal() +
  labs(
    title = "Confusion Matrix – Midfielders",
    x     = "Predicted Value",
    y     = "True Value"
  ) +
  theme(
    axis.text         = element_text(size = 13, color = "black"),
    axis.text.y       = element_text(angle = 90, hjust = 0.5),
    axis.title        = element_text(size = 13, color = "black"),
    plot.title        = element_text(face = "bold", size = 14, hjust = 0.5)
  )

print(mf_conf_matrix_g)



# --- Forwards ---
fw_data <- subset(data, FW == 1)
fw_data$transfer <- factor(fw_data$transfer)
fw_splits <- three_way_split(fw_data, "transfer")
fw_train  <- fw_splits$train
fw_val    <- fw_splits$validation

fw_down <- downSample(
  x     = fw_train[, setdiff(names(fw_train), "transfer")],
  y     = fw_train$transfer,
  yname = "transfer"
)
fw_rf    <- randomForest(
  transfer ~ .,
  data   = fw_down,
  ntree  = 500,
  mtry   = floor(sqrt(ncol(fw_down) - 1))
)

fw_preds       <- predict(fw_rf, fw_val)
fw_conf_matrix <- confusionMatrix(factor(fw_preds), factor(fw_val$transfer))
fw_conf_df     <- as.data.frame(fw_conf_matrix$table)
fw_conf_df$Prediction <- factor(
  fw_conf_df$Prediction,
  levels = c("0","1"),
  labels = c("no transfer","transferred")
)
fw_conf_df$Reference  <- factor(
  fw_conf_df$Reference,
  levels = c("0","1"),
  labels = c("no transfer","transferred")
)
fw_total_obs   <- sum(fw_conf_matrix$table)
fw_conf_df$Proportion <- fw_conf_df$Freq / fw_total_obs

fw_conf_matrix_g <- ggplot(fw_conf_df, aes(x = Prediction, y = Reference)) +
  geom_tile(fill = "white", color = "black") +
  geom_text(aes(label = paste0(
    Freq, " (", sprintf("%.2f", Proportion * 100), "%)"
  )), size = 5) +
  theme_minimal() +
  labs(
    title = "Confusion Matrix – Forwards",
    x     = "Predicted Value",
    y     = "True Value"
  ) +
  theme(
    axis.text         = element_text(size = 13, color = "black"),
    axis.text.y       = element_text(angle = 90, hjust = 0.5),
    axis.title        = element_text(size = 13, color = "black"),
    plot.title        = element_text(face = "bold", size = 14, hjust = 0.5)
  )

print(fw_conf_matrix_g)



# --- Defenders ---
df_data <- subset(data, DF == 1)
df_data$transfer <- factor(df_data$transfer)
df_splits <- three_way_split(df_data, "transfer")
df_train  <- df_splits$train
df_val    <- df_splits$validation

df_down <- downSample(
  x     = df_train[, setdiff(names(df_train), "transfer")],
  y     = df_train$transfer,
  yname = "transfer"
)
df_rf    <- randomForest(
  transfer ~ .,
  data   = df_down,
  ntree  = 500,
  mtry   = floor(sqrt(ncol(df_down) - 1))
)

df_preds       <- predict(df_rf, df_val)
df_conf_matrix <- confusionMatrix(factor(df_preds), factor(df_val$transfer))
df_conf_df     <- as.data.frame(df_conf_matrix$table)
df_conf_df$Prediction <- factor(
  df_conf_df$Prediction,
  levels = c("0","1"),
  labels = c("no transfer","transferred")
)
df_conf_df$Reference  <- factor(
  df_conf_df$Reference,
  levels = c("0","1"),
  labels = c("no transfer","transferred")
)
df_total_obs   <- sum(df_conf_matrix$table)
df_conf_df$Proportion <- df_conf_df$Freq / df_total_obs

df_conf_matrix_g <- ggplot(df_conf_df, aes(x = Prediction, y = Reference)) +
  geom_tile(fill = "white", color = "black") +
  geom_text(aes(label = paste0(
    Freq, " (", sprintf("%.2f", Proportion * 100), "%)"
  )), size = 5) +
  theme_minimal() +
  labs(
    title = "Confusion Matrix – Defenders",
    x     = "Predicted Value",
    y     = "True Value"
  ) +
  theme(
    axis.text         = element_text(size = 13, color = "black"),
    axis.text.y       = element_text(angle = 90, hjust = 0.5),
    axis.title        = element_text(size = 13, color = "black"),
    plot.title        = element_text(face = "bold", size = 14, hjust = 0.5)
  )

print(df_conf_matrix_g)

```
```{r}
plot_pos_cm <- function(pos, samp_type, df, splits_fn) {
  # subset & factor
  pos_data <- subset(df, df[[pos]] == 1)
  pos_data$transfer <- factor(pos_data$transfer)
  if (nrow(pos_data) < 50) return(NULL)
  
  # split
  sp    <- splits_fn(pos_data, "transfer")
  train <- sp$train
  valid <- sp$validation
  
  # sample
  if (samp_type == "Down") {
    sampled <- downSample(
      x     = train[, setdiff(names(train), "transfer")],
      y     = train$transfer,
      yname = "transfer"
    )
  } else {
    sampled <- upSample(
      x     = train[, setdiff(names(train), "transfer")],
      y     = train$transfer,
      yname = "transfer"
    )
  }
  
  # fit
  rf_mod <- randomForest(
    transfer ~ .,
    data   = sampled,
    ntree  = 500,
    mtry   = floor(sqrt(ncol(sampled) - 1))
  )
  
  # predict & cm
  preds      <- predict(rf_mod, valid)
  cm_matrix  <- confusionMatrix(factor(preds), valid$transfer)
  df_cm      <- as.data.frame(cm_matrix$table)
  
  # relabel
  df_cm$Prediction <- factor(
    df_cm$Prediction,
    levels = c("0","1"),
    labels = c("no transfer","transferred")
  )
  df_cm$Reference  <- factor(
    df_cm$Reference,
    levels = c("0","1"),
    labels = c("no transfer","transferred")
  )
  
  # proportion
  total <- sum(df_cm$Freq)
  df_cm$Proportion <- df_cm$Freq / total
  
  # plot
  ggplot(df_cm, aes(x = Prediction, y = Reference)) +
    geom_tile(fill = "white", color = "black") +
    geom_text(aes(label = paste0(
      Freq, " (", sprintf("%.2f", Proportion * 100), "%)"
    )), size = 5) +
    theme_minimal() +
    labs(
      title = paste("Confusion Matrix –", pos, "(", samp_type, "Sampling)"),
      x     = "Predicted Value",
      y     = "True Value"
    ) +
    theme(
      axis.text         = element_text(size = 13, color = "black"),
      axis.text.y       = element_text(angle = 90, hjust = 0.5),
      axis.title        = element_text(size = 13, color = "black"),
      plot.title        = element_text(face = "bold", size = 14, hjust = 0.5)
    )
}

# positions and sampling types
positions  <- c("MF","FW","DF")
samplings  <- c("Down","Up")

# iterate & print plots
set.seed(42)
for (pos in positions) {
  for (s in samplings) {
    p <- plot_pos_cm(pos, s, data, three_way_split)
    if (!is.null(p)) print(p)
  }
}
```



Random Forest Models / Position

```{r}
positions <- c("MF", "FW", "DF")

models <- list()
conf_matrices <- list()

for (pos in positions) {
  
  pos_data <- subset(data, data[[pos]] == 1)
  pos_data <- pos_data[, !(names(pos_data) %in% c("season", "player", "MD", "FW", "DF"))]
  pos_data$transfer <- as.factor(pos_data$transfer)
  
  if (nrow(pos_data) < 10) {
    cat("Not enough data for position", pos, "\n")
    next
  }
  
  # upSample to upsample ds
  # downSample to downsample ds
  ds <- upSample(x = pos_data[, setdiff(names(pos_data), "transfer")],
                   y = pos_data$transfer,
                   yname = "transfer")
  
  # Split the downsampled data into training and testing sets
  set.seed(42)
  trainIndex <- createDataPartition(ds$transfer, p = 0.7, list = FALSE)
  trainData <- ds[trainIndex, ]
  testData <- ds[-trainIndex, ]
  
  # Train the Random Forest model on the balanced dataset
  rf_model <- randomForest(transfer ~ ., 
                           data = trainData, 
                           ntree = 500, 
                           mtry = floor(sqrt(ncol(trainData) - 1)), 
                           importance = TRUE)
  
  models[[pos]] <- rf_model
  
  # Make predictions on the test set
  predictions <- predict(rf_model, testData)
  
  # Evaluate the model performance
  conf_mat <- confusionMatrix(predictions, testData$transfer)
  conf_matrices[[pos]] <- conf_mat
  
  cat("Confusion Matrix for", pos, "players:\n")
  print(conf_mat)
  cat("\n---------------------------------\n")
}
```

```{r}
#MF players:
cat("Model summary for MF players:\n")
print(models[["MF"]])
plot(models[["MF"]], main = "OOB Error for MD Players")
varImpPlot(models[["MF"]], main = "Variable Importance for MD Players")

#FW players:
cat("Model summary for FW players:\n")
print(models[["FW"]])
plot(models[["FW"]], main = "OOB Error for FW Players")
varImpPlot(models[["FW"]], main = "Variable Importance for FW Players")


#DF players:
cat("Model summary for DF players:\n")
print(models[["DF"]])
plot(models[["DF"]], main = "OOB Error for DF Players")
varImpPlot(models[["DF"]], main = "Variable Importance for DF Players")

```

```{r}
oob_data <- data.frame(
  trees = 1:nrow(models[["MF"]]$err.rate),
  OOB_Error = models[["MF"]]$err.rate[,"OOB"]
)

library(ggplot2)
ggplot(oob_data, aes(x = trees, y = OOB_Error)) +
  geom_line(color = "blue", size = 1.2) +
  labs(
    title = "OOB Error Rate for MF Players",
    x = "Number of Trees",
    y = "OOB Error"
  ) +
  theme_minimal()

importanceMF <- data.frame(
  Variable = rownames(models[["MF"]]$importance),
  Importance = models[["MF"]]$importance[,"MeanDecreaseAccuracy"]
)

# Order variables by importance
importanceMF <- importanceMF[order(importanceMF$Importance, decreasing = TRUE), ]
importanceMF$Variable <- str_to_title(gsub("_", " ", importanceMF$Variable))
importanceMF$Color <- rep(c("steelblue", "tomato"), length.out = nrow(importanceMF))

ggplot(importanceMF, aes(x = reorder(Variable, Importance), y = Importance, fill = Color)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(
    title = "Variable Importance for Midfielders (MDA)",
    x = "Variables",
    y = "Importance"
  ) +
  scale_fill_identity() +
  theme_minimal()

importanceDF <- data.frame(
  Variable = rownames(models[["DF"]]$importance),
  Importance = models[["DF"]]$importance[,"MeanDecreaseAccuracy"]
)

# Order variables by importance
importanceDF<- importanceDF[order(importanceDF$Importance, decreasing = TRUE), ]
importanceDF$Variable <- str_to_title(gsub("_", " ", importanceDF$Variable))
importanceDF$Color <- rep(c("steelblue", "tomato"), length.out = nrow(importanceDF))

ggplot(importanceDF, aes(x = reorder(Variable, Importance), y = Importance, fill = Color)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(
    title = "Variable Importance for Defenders (MDA)",
    x = "Variables",
    y = "Importance"
  ) +
  scale_fill_identity() +
  theme_minimal()

importanceFW <- data.frame(
  Variable = rownames(models[["FW"]]$importance),
  Importance = models[["FW"]]$importance[,"MeanDecreaseAccuracy"]
)

# Order variables by importance
importanceFW <- importanceFW[order(importanceFW$Importance, decreasing = TRUE), ]
importanceFW$Variable <- str_to_title(gsub("_", " ", importanceFW$Variable))
importanceFW$Color <- rep(c("steelblue", "tomato"), length.out = nrow(importanceFW))

ggplot(importanceFW, aes(x = reorder(Variable, Importance), y = Importance, fill = Color)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(
    title = "Variable Importance for Forwards (MDA)",
    x = "Variables",
    y = "Importance"
  ) +
  scale_fill_identity() +
  theme_minimal()
```
```{r}
performance_table <- do.call(rbind, lapply(names(conf_matrices), function(pos) {
  cm <- conf_matrices[[pos]]
  data.frame(
    Position = pos,
    Accuracy = round(as.numeric(cm$overall["Accuracy"]), 3),
    Sensitivity = round(as.numeric(cm$byClass["Sensitivity"]), 3),
    Specificity = round(as.numeric(cm$byClass["Specificity"]), 3)
  )
}))

kable(performance_table, 
      caption = "RF Model Performance Metrics by Position",
      col.names = c("Position", "Accuracy", "Sensitivity", "Specificity"))

performance_table <- do.call(rbind, lapply(names(conf_matrices), function(pos) {
  cm <- conf_matrices[[pos]]
  data.frame(
    Position = pos,
    Accuracy = round(as.numeric(cm$overall["Accuracy"]), 3),
    Sensitivity = round(as.numeric(cm$byClass["Sensitivity"]), 3),
    Specificity = round(as.numeric(cm$byClass["Specificity"]), 3)
  )
}))

performance_table <- do.call(rbind, lapply(names(conf_matrices), function(pos) {
  cm <- conf_matrices[[pos]]
  data.frame(
    Position = pos,
    Accuracy = round(as.numeric(cm$overall["Accuracy"]), 3),
    Sensitivity = round(as.numeric(cm$byClass["Sensitivity"]), 3),
    Specificity = round(as.numeric(cm$byClass["Specificity"]), 3)
  )
}))

# Create a title for the summary table
summary_title <- textGrob("RF Model Performance Metrics by Position",
                            gp = gpar(fontsize = 14, fontface = "bold"))

# Convert the summary data frame into a table graphic
performance_table_grob <- tableGrob(performance_table)

# Arrange the title and table vertically
grid.arrange(summary_title, performance_table_grob, 
             nrow = 2, 
             heights = c(0.15, 0.85))


# Now, loop over each confusion matrix to display it nicely
for (pos in names(conf_matrices)) {
  # Create a title for each confusion matrix
  cm_title <- textGrob(paste("Confusion Matrix for", pos, "Players"),
                       gp = gpar(fontsize = 14, fontface = "bold"))
  # Convert the confusion matrix table into a table graphic
  cm_grob <- tableGrob(as.table(conf_matrices[[pos]]$table))
  
  # Arrange the title and the matrix table together
  grid.arrange(cm_title, cm_grob, 
               nrow = 2, 
               heights = c(0.15, 0.85))
}

```
```{r}
importance_data <- data.frame(
  Variable = rownames(models[["MF"]]$importance),
  Importance = models[["MF"]]$importance[,"MeanDecreaseAccuracy"]
)

# Remove underscores, replace with spaces, and convert text to title case
importance_data$Variable <- str_to_title(gsub("_", " ", importance_data$Variable))

# Order the data by importance, descending
importance_data <- importance_data[order(importance_data$Importance, decreasing = TRUE), ]

# Create an alternating color vector (for example, between "steelblue" and "tomato")
importance_data$Color <- rep(c("steelblue", "tomato"), length.out = nrow(importance_data))

# Plot the variable importance using ggplot2 with the cleaned labels
ggplot(importance_data, aes(x = reorder(Variable, Importance), y = Importance, fill = Color)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(
    title = "Variable Importance (MeanDecreaseAccuracy)",
    x = "Variables",
    y = "Importance"
  ) +
  scale_fill_identity() +
  theme_minimal()

importance_data <- data.frame(
  Variable = rownames(models[["MF"]]$importance),
  Importance = models[["MF"]]$importance[,"MeanDecreaseAccuracy"]
)

# Remove underscores, replace with spaces, and convert text to title case
importance_data$Variable <- str_to_title(gsub("_", " ", importance_data$Variable))

# Order the data by importance, descending
importance_data <- importance_data[order(importance_data$Importance, decreasing = TRUE), ]

# Create an alternating color vector (for example, between "steelblue" and "tomato")
importance_data$Color <- rep(c("steelblue", "tomato"), length.out = nrow(importance_data))

# Plot the variable importance using ggplot2 with the cleaned labels
ggplot(importance_data, aes(x = reorder(Variable, Importance), y = Importance, fill = Color)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(
    title = "Variable Importance (MeanDecreaseAccuracy)",
    x = "Variables",
    y = "Importance"
  ) +
  scale_fill_identity() +
  theme_minimal()
```

